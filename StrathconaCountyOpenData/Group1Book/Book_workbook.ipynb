{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to install libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user spaCy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cells to load libaries and pre-defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/callysto/hackathon/master/Group1_Book/helper_code/book1.py -P helper_code -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_book_df(chapters):\n",
    "    book_df = pd.DataFrame(columns=[\"text\", \"part-of-speech\",\"lemma\",\"chapter\"])\n",
    "    for i in range(len(chapters)):\n",
    "        chapter_tokens = nlp(chapters[i])\n",
    "        for token in chapter_tokens:\n",
    "             if ((token.pos_==\"VERB\") | (token.pos_==\"NOUN\") | (token.pos_==\"ADJ\") | (token.pos_== \"PROPN\")):\n",
    "                    book_df = book_df.append({\"text\": token.text,\n",
    "                             \"part-of-speech\":  token.pos_,\n",
    "                             \"lemma\" : token.lemma_.strip().lower(),\n",
    "                             \"chapter\": i+1\n",
    "                              }, ignore_index=True)\n",
    "    return book_df\n",
    "\n",
    "def get_speechparts_by_chapter(book_df):\n",
    "    result = book_df.groupby([\"chapter\", \"part-of-speech\"]).size().reset_index(name=\"count\").\\\n",
    "                          pivot(index=\"chapter\", columns='part-of-speech',values=\"count\").reset_index().\\\n",
    "                          rename_axis(None,axis=\"columns\").set_index(\"chapter\")\n",
    "    return result \n",
    "\n",
    "def get_counts(book_df, value):\n",
    "    result = book_df.groupby(value).size().reset_index(name='count').set_index(value).sort_values(['count'], ascending=False)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_counts_by_chapters(book_df):\n",
    "    result = book_df.groupby([\"chapter\", \"lemma\"]).size().reset_index(name=\"count\").\\\n",
    "                                     pivot(index=\"chapter\", columns='lemma',values=\"count\").reset_index().\\\n",
    "                                    rename_axis(None,axis=\"columns\").set_index(\"chapter\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries and helper code\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from helper_code.book1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group goal\n",
    "\n",
    " \n",
    "Go through the \"Alice's Adventures in Wonderland\" analysis below, work on challenges, and try modifying the code.\n",
    "\n",
    "**Extra challenge**:\n",
    "\n",
    "Explore the \"Adventures of Tom Sawyer\" book to show interesting results and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download  book from project Guttenberg website\n",
    "\n",
    "This book was downloaded from project Gutenberg website.\n",
    "\n",
    "**Project Gutenberg** is a library of over 60,000 free eBooks\n",
    "\n",
    "[This link](http://www.gutenberg.org/ebooks/search/?sort_order=downloads) shows the most popular books. \n",
    "\n",
    "\n",
    "In this notebook we are going to look at \"Alice's Adventures in Wonderland\" book.  \n",
    "\"The Adventures of Tom Sawyer\" is downloaded as well for extra challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files names for both books\n",
    "alice_filename = \"alice.txt\"\n",
    "tom_filename = \"tom.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying files from cloud object storage\n",
    "alice_url=\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_d22d1e3f28be45209ba8f660295c84cf/hackaton/alice.txt\"\n",
    "urllib.request.urlretrieve(alice_url, alice_filename)\n",
    "\n",
    "\n",
    "tom_url=\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_d22d1e3f28be45209ba8f660295c84cf/hackaton/tom.txt\"\n",
    "urllib.request.urlretrieve(tom_url, tom_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the book into variable 'book'\n",
    "with open(alice_filename, 'r') as text_file:\n",
    "    book = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the entire book on the screen\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many characters are in the book?\n",
    "len(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the book by chapter\n",
    "chapters = re.split(\"CHAPTER\\s+[IVXLCDM]+.\", book)\n",
    "\n",
    "# strip off any whitespace at the very beginning and very end of each chapter.\n",
    "chapters = [chapter.strip() for chapter in chapters]\n",
    "\n",
    "# remove tabs\n",
    "chapters = [re.sub(\"\\n\", \" \", c) for c in chapters]\n",
    "\n",
    "#select only chapters that have more than 1000 characters (to exclude table of contents, title, etc.)\n",
    "chapters = [c for c in chapters if len(c)>1000]\n",
    " \n",
    "# number of chapters\n",
    "print(len(chapters), \" chapters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe selecting only nouns, proper nouns, verbs. and adjectives per chapter\n",
    "\n",
    "- **text**: actual word\n",
    "- **part-of-speech**:  ADJ, PROPN, VERB, or NOUN\n",
    "- **lemma**: headword\n",
    "- **chapter**: chapter number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will run 3-5 mins!!!\n",
    "\n",
    "#create a dataframe from the book\n",
    "book_df = get_book_df(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of the dataframe\n",
    "book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many rows (individual words) and columns do we have?\n",
    "book_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluding lemma equal to '’s' and '’'\n",
    "book_df = book_df[(book_df[\"lemma\"]!='’s') & (book_df[\"lemma\"]!='’')]\n",
    "book_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjectives, nouns, proper nouns, and verbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we group by \"part-of-speech\" column and count the number of rows\n",
    "counts_by_part_of_speech = book_df.groupby(\"part-of-speech\").size()\n",
    "\n",
    "counts_by_part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pie chart - figure size 5 by 5 to make pie even circle\n",
    "counts_by_part_of_speech.plot(kind=\"pie\",figsize=(5,5))\n",
    "\n",
    "#set x and y axis labels to blanks\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: \n",
    " - Try grouping by different column: if you change `groupby(\"part-of-speech\")` to `groupby(\"chapter\")` what will it give you?\n",
    " - Experiment with different kinds of plots: try  changing `plot(kind=\"pie\")` to `plot()` or `plot(kind=\"bar\")` or `plot(kind=\"barh\")`. Which of these better represents the data?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjective/nouns/proper nouns and verbs  per chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we call a function to get total number of all parts of speech per chapter, \n",
    "speech_parts_by_chapter = get_speechparts_by_chapter(book_df)\n",
    "\n",
    "#print data on the screen\n",
    "speech_parts_by_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different kind of plot - area\n",
    "speech_parts_by_chapter.plot(kind=\"area\",figsize=(18,8))\n",
    "\n",
    "plt.xlabel(\"Chapter\", size = 16)\n",
    "plt.ylabel(\"Counts\", size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    " - Experiment with plots: try changing `plot(kind=\"area\")` to `plot()` or `plot(kind=\"bar\")` or `plot(kind=\"bar\",stacked=True)`. \n",
    "\n",
    " - What kind of plot can better visually demonstrate which chapter has the largest number of verbs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to find the chapter with max number of words is **sorting**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_values() function - sorts by a column or set of columns\n",
    "speech_parts_by_chapter.sort_values(\"VERB\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - Find the  chapter that has the most **NOUN**s\n",
    " - Find the chapter that hast the **fewest** adjectives\n",
    " - Try plotting the results\n",
    " - Try two new kinds of plots -histogram and boxplot. Can you figure out how to interpret them?\n",
    "     - Use  `plot(kind=\"boxplot\")`\n",
    "     - Use  `plot(kind=\"hist\",alpha=0.4)` (try changing alpha)\n",
    "     \n",
    "More information on [histograms](https://www.mathsisfun.com/data/histograms.html) and [boxplots](https://www.mathsisfun.com/definitions/box-and-whisker-plot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to count the number of rows  for every \"lemma\" \n",
    "\n",
    "word_counts = get_counts(book_df, \"lemma\")\n",
    "\n",
    "#print top 10 most frequent words on the screen\n",
    "word_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - Try using \"text\" column instead of \"lemma\" - why do you get different results?\n",
    " - Plot the results using your choice of plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The top 10 most common adjectives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to adjectives\n",
    "adjectives = book_df[book_df[\"part-of-speech\"]==\"ADJ\"]\n",
    "\n",
    "adjectives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to count the number of adjectives\n",
    "adjective_counts = get_counts(adjectives, \"lemma\")\n",
    "\n",
    "adjective_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the top 10 adjectives:\n",
    "adjective_counts.head(10).plot(kind=\"bar\",figsize=(18, 8))\n",
    "\n",
    "#set x and y axis labels\n",
    "plt.ylabel(\"Counts\", size = 16)\n",
    "plt.xlabel(\"Lemma\", size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - Find the top 10 most common nouns and verbs\n",
    " - Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the top 15 most common  proper nouns, how does the number vary from chapter to chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to proper nouns\n",
    "propnouns = book_df[book_df[\"part-of-speech\"]==\"PROPN\"]\n",
    "\n",
    "propnouns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many most frequent proper nouns do we want to analyse\n",
    "num_words = 15\n",
    "\n",
    "#call function to count the number of proper nouns \n",
    "top_propnouns = get_counts(propnouns, \"lemma\")\n",
    "\n",
    "#get the top proper nouns \n",
    "top_propnouns = top_propnouns.head(num_words).index\n",
    "\n",
    "#transform them into list\n",
    "top_propnouns = list(top_propnouns)\n",
    "\n",
    "#print on the screen\n",
    "top_propnouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to the top proper nouns\n",
    "character_by_chapter = book_df[book_df[\"lemma\"].isin(top_propnouns)]\n",
    "\n",
    "character_by_chapter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#what is the distribution of top proper nouns per chapter?\n",
    "# call function to form resulting dataframe \n",
    "counts_by_chapter = get_counts_by_chapters(character_by_chapter)\n",
    "\n",
    "#display on the screen\n",
    "counts_by_chapter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the main characters in every chapter?\n",
    "#we use colormap \"tab20\" to extend the default number of colors\n",
    "counts_by_chapter.plot(kind=\"bar\",figsize=(18,8),stacked = True, cmap=\"tab20\")\n",
    "\n",
    "#set x and y axis labels\n",
    "plt.ylabel(\"Counts\", size = 16)\n",
    "plt.xlabel(\"Chapter\", size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - Try experimenting with the number of proper nouns (change `num_words`)\n",
    " - Try doing the same thing with adjectives, nouns, or/and verbs - can you guess whats going on in each chapter based on these plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra\n",
    "Now let's try doing the same thing but using **percentage** instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will make a copy of dataframe to work with percentages\n",
    "counts_percent = counts_by_chapter.copy()\n",
    "\n",
    "#create addtional column - sum of words per chapter (axis =1 - means -sum by row)\n",
    "counts_percent[\"sum\"] = counts_percent.sum(axis = 1)\n",
    "\n",
    "#divide evry column by sum\n",
    "counts_percent = counts_percent.iloc[:,0:num_words].divide(counts_percent[\"sum\"],axis=0)\n",
    "\n",
    "#multiply every column by 100\n",
    "counts_percent = counts_percent.iloc[:,0:num_words].multiply(100,axis=0)\n",
    "\n",
    "#we choose area plot this time\n",
    "counts_percent.plot(kind=\"area\",figsize=(18,8),cmap=\"tab20\")\n",
    "\n",
    "#set x and y axis labels\n",
    "plt.ylabel(\"Percent\", size = 16)\n",
    "plt.xlabel(\"Chapter\", size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/callysto/callysto-sample-notebooks/blob/master/notebooks/images/Callysto_Notebook-Banners_Bottom_06.06.18.jpg?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
